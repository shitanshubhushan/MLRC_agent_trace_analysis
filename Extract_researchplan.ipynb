{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from pydantic import BaseModel\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_agent_file(folder_path):\n",
    "    # Find all agent files in the folder\n",
    "    agent_files = glob.glob(os.path.join(folder_path, \"agent_*_*.json\"))\n",
    "    \n",
    "    if not agent_files:\n",
    "        return None\n",
    "    \n",
    "    # Extract agent numbers and find the highest one\n",
    "    max_agent_num = 0\n",
    "    max_agent_file = None\n",
    "    \n",
    "    for file in agent_files:\n",
    "        # Extract the number from filename using regex\n",
    "        match = re.search(r\"agent_(\\d+)_\\d+\\.json\", file)\n",
    "        if match:\n",
    "            agent_num = int(match.group(1))\n",
    "            if agent_num > max_agent_num:\n",
    "                max_agent_num = agent_num\n",
    "                max_agent_file = file\n",
    "    \n",
    "    return max_agent_file\n",
    "\n",
    "def extract_history_steps(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        # Extract history_steps without observation field\n",
    "        history_steps = data.get('history_steps', [])\n",
    "        \n",
    "        # Remove observation field from each step\n",
    "        for step in history_steps:\n",
    "            if 'observation' in step:\n",
    "                del step['observation']\n",
    "\n",
    "            if 'action' in step and isinstance(step['action'], dict):\n",
    "                # if 'Research Plan and Status' in step['action']:\n",
    "                #     del step['action']['Research Plan and Status']\n",
    "                if 'Fact Check' in step['action']:\n",
    "                    del step['action']['Fact Check']\n",
    "                \n",
    "        return history_steps\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_task_name_and_id(folder_path):\n",
    "    # Split the path into components\n",
    "    parts = folder_path.split(os.sep)\n",
    "    \n",
    "    # Look for task name and run ID in the path\n",
    "    task_name = None\n",
    "    run_id = None\n",
    "    \n",
    "    for i, part in enumerate(parts):\n",
    "        if i < len(parts) - 2 and parts[i+2].startswith('0'):  # Assuming run IDs start with numbers\n",
    "            task_name = part\n",
    "            run_id = parts[i+2]\n",
    "            break\n",
    "    \n",
    "    return task_name, run_id\n",
    "\n",
    "def process_all_folders(base_path, output_base):\n",
    "    # Walk through directory structure\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        # Check if this folder contains agent files\n",
    "        agent_files = [f for f in files if f.startswith(\"agent_\") and f.endswith(\".json\")]\n",
    "        if agent_files:\n",
    "            last_agent = get_last_agent_file(root)\n",
    "            if last_agent:\n",
    "                history = extract_history_steps(last_agent)\n",
    "                if history:\n",
    "                    # Extract task name and run ID from the folder path\n",
    "                    task_name, run_id = extract_task_name_and_id(root)\n",
    "                    \n",
    "                    if task_name and run_id:\n",
    "                        # Create output directory\n",
    "                        output_dir = os.path.join(output_base, task_name, run_id)\n",
    "                        os.makedirs(output_dir, exist_ok=True)\n",
    "                        \n",
    "                        # Save the extracted history\n",
    "                        output_file = os.path.join(output_dir, \"output.json\")\n",
    "                        with open(output_file, 'w') as f:\n",
    "                            json.dump(history, f, indent=2)\n",
    "                        \n",
    "                        print(f\"Extracted history from {root} saved to {output_file}\")\n",
    "                    else:\n",
    "                        print(f\"Could not determine task name and run ID for {root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted history from data/machine_unlearning/claude-3-5-sonnet-v2/0203205627_279760/agent_log saved to Steps_RP/machine_unlearning/0203205627_279760/output.json\n",
      "Extracted history from data/machine_unlearning/claude-3-5-sonnet-v2/0203205627_2107738/agent_log saved to Steps_RP/machine_unlearning/0203205627_2107738/output.json\n",
      "Extracted history from data/machine_unlearning/claude-3-5-sonnet-v2/0204004906_2156777/agent_log saved to Steps_RP/machine_unlearning/0204004906_2156777/output.json\n",
      "Extracted history from data/machine_unlearning/claude-3-5-sonnet-v2/0204021048_1005508/agent_log saved to Steps_RP/machine_unlearning/0204021048_1005508/output.json\n",
      "Extracted history from data/machine_unlearning/claude-3-5-sonnet-v2/0204000906_980483/agent_log saved to Steps_RP/machine_unlearning/0204000906_980483/output.json\n",
      "Extracted history from data/machine_unlearning/claude-3-5-sonnet-v2/0204002434_497948/agent_log saved to Steps_RP/machine_unlearning/0204002434_497948/output.json\n",
      "Extracted history from data/machine_unlearning/claude-3-5-sonnet-v2/0203235437_311468/agent_log saved to Steps_RP/machine_unlearning/0203235437_311468/output.json\n",
      "Extracted history from data/machine_unlearning/claude-3-5-sonnet-v2/0203205627_931197/agent_log saved to Steps_RP/machine_unlearning/0203205627_931197/output.json\n",
      "Extracted history from data/meta-learning/claude-3-5-sonnet-v2/0211164506_234282/agent_log saved to Steps_RP/meta-learning/0211164506_234282/output.json\n",
      "Extracted history from data/meta-learning/claude-3-5-sonnet-v2/0212001115_3514169/agent_log saved to Steps_RP/meta-learning/0212001115_3514169/output.json\n",
      "Extracted history from data/meta-learning/claude-3-5-sonnet-v2/0212223706_984095/agent_log saved to Steps_RP/meta-learning/0212223706_984095/output.json\n",
      "Extracted history from data/meta-learning/claude-3-5-sonnet-v2/0212230702_2432398/agent_log saved to Steps_RP/meta-learning/0212230702_2432398/output.json\n",
      "Extracted history from data/meta-learning/claude-3-5-sonnet-v2/0212021042_3840295/agent_log saved to Steps_RP/meta-learning/0212021042_3840295/output.json\n",
      "Extracted history from data/meta-learning/claude-3-5-sonnet-v2/0211142216_3241844/agent_log saved to Steps_RP/meta-learning/0211142216_3241844/output.json\n",
      "Extracted history from data/meta-learning/claude-3-5-sonnet-v2/0212235435_1003034/agent_log saved to Steps_RP/meta-learning/0212235435_1003034/output.json\n",
      "Extracted history from data/meta-learning/claude-3-5-sonnet-v2/0211192713_3421734/agent_log saved to Steps_RP/meta-learning/0211192713_3421734/output.json\n",
      "Extracted history from data/llm-merging/claude-3-5-sonnet-v2/0121081654/agent_log saved to Steps_RP/llm-merging/0121081654/output.json\n",
      "Extracted history from data/llm-merging/claude-3-5-sonnet-v2/0124071448/agent_log saved to Steps_RP/llm-merging/0124071448/output.json\n",
      "Extracted history from data/llm-merging/claude-3-5-sonnet-v2/0124110854/agent_log saved to Steps_RP/llm-merging/0124110854/output.json\n",
      "Extracted history from data/llm-merging/claude-3-5-sonnet-v2/0122121253/agent_log saved to Steps_RP/llm-merging/0122121253/output.json\n",
      "Extracted history from data/llm-merging/claude-3-5-sonnet-v2/0122132158/agent_log saved to Steps_RP/llm-merging/0122132158/output.json\n",
      "Extracted history from data/llm-merging/claude-3-5-sonnet-v2/0121200118/agent_log saved to Steps_RP/llm-merging/0121200118/output.json\n",
      "Extracted history from data/llm-merging/claude-3-5-sonnet-v2/0121073211/agent_log saved to Steps_RP/llm-merging/0121073211/output.json\n",
      "Extracted history from data/llm-merging/claude-3-5-sonnet-v2/0121214229/agent_log saved to Steps_RP/llm-merging/0121214229/output.json\n",
      "Extracted history from data/backdoor-trigger-recovery/claude-3-5-sonnet-v2/0124032241/agent_log saved to Steps_RP/backdoor-trigger-recovery/0124032241/output.json\n",
      "Extracted history from data/backdoor-trigger-recovery/claude-3-5-sonnet-v2/0121200721/agent_log saved to Steps_RP/backdoor-trigger-recovery/0121200721/output.json\n",
      "Extracted history from data/backdoor-trigger-recovery/claude-3-5-sonnet-v2/0124144709/agent_log saved to Steps_RP/backdoor-trigger-recovery/0124144709/output.json\n",
      "Extracted history from data/backdoor-trigger-recovery/claude-3-5-sonnet-v2/0122092147/agent_log saved to Steps_RP/backdoor-trigger-recovery/0122092147/output.json\n",
      "Extracted history from data/backdoor-trigger-recovery/claude-3-5-sonnet-v2/0121045246/agent_log saved to Steps_RP/backdoor-trigger-recovery/0121045246/output.json\n",
      "Extracted history from data/backdoor-trigger-recovery/claude-3-5-sonnet-v2/0122164524/agent_log saved to Steps_RP/backdoor-trigger-recovery/0122164524/output.json\n",
      "Extracted history from data/backdoor-trigger-recovery/claude-3-5-sonnet-v2/0121105812/agent_log saved to Steps_RP/backdoor-trigger-recovery/0121105812/output.json\n",
      "Extracted history from data/backdoor-trigger-recovery/claude-3-5-sonnet-v2/0122014648/agent_log saved to Steps_RP/backdoor-trigger-recovery/0122014648/output.json\n",
      "Extracted history from data/perception_temporal_action_loc/claude-3-5-sonnet-v2/0130064726/agent_log saved to Steps_RP/perception_temporal_action_loc/0130064726/output.json\n",
      "Extracted history from data/perception_temporal_action_loc/claude-3-5-sonnet-v2/0130104224/agent_log saved to Steps_RP/perception_temporal_action_loc/0130104224/output.json\n",
      "Extracted history from data/perception_temporal_action_loc/claude-3-5-sonnet-v2/0130021740/agent_log saved to Steps_RP/perception_temporal_action_loc/0130021740/output.json\n",
      "Extracted history from data/perception_temporal_action_loc/claude-3-5-sonnet-v2/0130045001/agent_log saved to Steps_RP/perception_temporal_action_loc/0130045001/output.json\n",
      "Extracted history from data/perception_temporal_action_loc/claude-3-5-sonnet-v2/0130093111/agent_log saved to Steps_RP/perception_temporal_action_loc/0130093111/output.json\n",
      "Extracted history from data/perception_temporal_action_loc/claude-3-5-sonnet-v2/0130112112/agent_log saved to Steps_RP/perception_temporal_action_loc/0130112112/output.json\n",
      "Extracted history from data/perception_temporal_action_loc/claude-3-5-sonnet-v2/0130102918/agent_log saved to Steps_RP/perception_temporal_action_loc/0130102918/output.json\n",
      "Extracted history from data/perception_temporal_action_loc/claude-3-5-sonnet-v2/0130102836/agent_log saved to Steps_RP/perception_temporal_action_loc/0130102836/output.json\n"
     ]
    }
   ],
   "source": [
    "base_directory = \"data\"\n",
    "output_directory = \"Steps_RP\"\n",
    "\n",
    "# Create the base output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Process all folders\n",
    "process_all_folders(base_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_analyze_files(steps_dir):\n",
    "    \n",
    "    # Create empty dataframe with our desired columns\n",
    "    results_df = pd.DataFrame(columns=[\"Task\", \"Run_ID\", \"Summary\"])\n",
    "    \n",
    "    failed_folders = []\n",
    "    retry_stats = []\n",
    "    max_retries = 5  # Maximum number of retries before giving up\n",
    "    \n",
    "    # Walk through the Steps directory\n",
    "    for task_name in os.listdir(steps_dir):\n",
    "        task_dir = os.path.join(steps_dir, task_name)\n",
    "        if not os.path.isdir(task_dir):\n",
    "            continue\n",
    "        \n",
    "        for run_id in os.listdir(task_dir):\n",
    "            run_dir = os.path.join(task_dir, run_id)\n",
    "            if not os.path.isdir(run_dir):\n",
    "                continue\n",
    "                \n",
    "            output_file = os.path.join(run_dir, \"output.json\")\n",
    "            if not os.path.exists(output_file):\n",
    "                print(f\"No output.json found in {run_dir}\")\n",
    "                continue\n",
    "                \n",
    "            # Read the output.json file\n",
    "            try:\n",
    "                with open(output_file, 'r') as f:\n",
    "                    output_data = json.load(f)\n",
    "                \n",
    "                # Skip empty files or invalid data\n",
    "                if not output_data or not isinstance(output_data, list) or len(output_data) == 0:\n",
    "                    print(f\"Empty or invalid data in {run_dir}/output.json\")\n",
    "                    failed_folders.append(f\"{task_name}/{run_id}\")\n",
    "                    continue\n",
    "                \n",
    "                # Convert output_data to pretty-printed string for the prompt\n",
    "                output_json_str = json.dumps(output_data, indent=2)\n",
    "                \n",
    "                # Create prompt for the approach summary\n",
    "                prompt = f\"\"\"\n",
    "                You are a researcher, given the following trace of an AI agent doing ML research challenges:\n",
    "                {output_json_str}\n",
    "                \n",
    "                Analyze what the agent did and provide a concise 50-word summary focusing on whether \n",
    "                the agent took an engineering approach (implementing known methods) or a scientific \n",
    "                research approach (developing novel theories).\n",
    "                \n",
    "                Just return the plain text summary without any JSON structure or additional formatting.\n",
    "                Keep the summary EXACTLY 50 words or fewer.\n",
    "                \"\"\"\n",
    "                \n",
    "                print(f\"Processing {task_name}/{run_id}...\")\n",
    "                \n",
    "                # Retry loop for handling API errors\n",
    "                retry_count = 0\n",
    "                success = False\n",
    "                \n",
    "                while not success and retry_count < max_retries:\n",
    "                    try:\n",
    "                        # Call the API\n",
    "                        completion = client.beta.chat.completions.parse(\n",
    "                            model=\"gpt-4o-mini\",\n",
    "                            messages=[\n",
    "                                {\n",
    "                                    \"role\": \"user\",\n",
    "                                    \"content\": prompt\n",
    "                                }\n",
    "                            ]\n",
    "                        )\n",
    "                        \n",
    "                        # Extract the response\n",
    "                        response_content = completion.choices[0].message.content\n",
    "                        \n",
    "                        # No need to validate word count - any response is accepted\n",
    "                        success = True\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        retry_count += 1\n",
    "                        print(f\"Error processing {task_name}/{run_id} (attempt {retry_count}/{max_retries}): {str(e)}\")\n",
    "                        time.sleep(2)\n",
    "                \n",
    "                # After the retry loop, check if we had success\n",
    "                if success:\n",
    "                    # Save the analysis result\n",
    "                    summary_file = os.path.join(run_dir, \"summary.txt\")\n",
    "                    with open(summary_file, 'w') as f:\n",
    "                        f.write(response_content)\n",
    "                    \n",
    "                    # Add row to our dataframe\n",
    "                    new_row = pd.DataFrame({\"Task\": [task_name], \"Run_ID\": [run_id], \"Summary\": [response_content]})\n",
    "                    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "                    \n",
    "                    # Record retry stats if we needed retries\n",
    "                    if retry_count > 0:\n",
    "                        retry_stats.append(f\"{task_name}/{run_id}: Succeeded after {retry_count} retries\")\n",
    "                        \n",
    "                    #print(f\"Summary saved to {analysis_file}\" + (f\" after {retry_count} retries\" if retry_count > 0 else \"\"))\n",
    "                    \n",
    "                else:\n",
    "                    # All retries failed\n",
    "                    print(f\"Failed to get valid summary for {task_name}/{run_id} after {max_retries} attempts\")\n",
    "                    failed_folders.append(f\"{task_name}/{run_id}\")\n",
    "                    retry_stats.append(f\"{task_name}/{run_id}: Failed after {max_retries} retries\")\n",
    "                \n",
    "                # Add a small delay to avoid rate limiting\n",
    "                time.sleep(1)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file for {task_name}/{run_id}: {str(e)}\")\n",
    "                failed_folders.append(f\"{task_name}/{run_id}\")\n",
    "    \n",
    "    # Save the compiled results as CSV\n",
    "    compiled_results_file = os.path.join(steps_dir, \"compiled_summaries.csv\")\n",
    "    results_df.to_csv(compiled_results_file, index=False)\n",
    "    \n",
    "    # Also save as Excel for easier viewing\n",
    "    excel_file = os.path.join(steps_dir, \"compiled_summaries.xlsx\")\n",
    "    results_df.to_excel(excel_file, index=False)\n",
    "    \n",
    "    # Save the list of failed folders\n",
    "    failed_folders_file = os.path.join(steps_dir, \"failed_folders.txt\")\n",
    "    with open(failed_folders_file, 'w') as f:\n",
    "        for folder in failed_folders:\n",
    "            f.write(f\"{folder}\\n\")\n",
    "    \n",
    "    # Save the retry statistics\n",
    "    retry_stats_file = os.path.join(steps_dir, \"retry_stats.txt\")\n",
    "    with open(retry_stats_file, 'w') as f:\n",
    "        for stat in retry_stats:\n",
    "            f.write(f\"{stat}\\n\")\n",
    "    \n",
    "    print(f\"Compiled summaries saved to {compiled_results_file} and {excel_file}\")\n",
    "    print(f\"Failed folders list saved to {failed_folders_file}\")\n",
    "    print(f\"Retry statistics saved to {retry_stats_file}\")\n",
    "    print(f\"Total failed folders: {len(failed_folders)}\")\n",
    "    print(f\"Folders that needed retries: {len(retry_stats)}\")\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing machine_unlearning/0203205627_279760...\n",
      "Processing machine_unlearning/0203205627_2107738...\n",
      "Processing machine_unlearning/0204004906_2156777...\n",
      "Processing machine_unlearning/0204021048_1005508...\n",
      "Processing machine_unlearning/0204000906_980483...\n",
      "Processing machine_unlearning/0204002434_497948...\n",
      "Processing machine_unlearning/0203235437_311468...\n",
      "Processing machine_unlearning/0203205627_931197...\n",
      "Processing meta-learning/0211164506_234282...\n",
      "Processing meta-learning/0212001115_3514169...\n",
      "Processing meta-learning/0212223706_984095...\n",
      "Processing meta-learning/0212230702_2432398...\n",
      "Processing meta-learning/0212021042_3840295...\n",
      "Processing meta-learning/0211142216_3241844...\n",
      "Processing meta-learning/0212235435_1003034...\n",
      "Processing meta-learning/0211192713_3421734...\n",
      "Processing llm-merging/0121081654...\n",
      "Processing llm-merging/0124071448...\n",
      "Processing llm-merging/0124110854...\n",
      "Processing llm-merging/0122121253...\n",
      "Processing llm-merging/0122132158...\n",
      "Processing llm-merging/0121200118...\n",
      "Processing llm-merging/0121073211...\n",
      "Processing llm-merging/0121214229...\n",
      "Processing backdoor-trigger-recovery/0124032241...\n",
      "Processing backdoor-trigger-recovery/0121200721...\n",
      "Processing backdoor-trigger-recovery/0124144709...\n",
      "Processing backdoor-trigger-recovery/0122092147...\n",
      "Processing backdoor-trigger-recovery/0121045246...\n",
      "Processing backdoor-trigger-recovery/0122164524...\n",
      "Processing backdoor-trigger-recovery/0121105812...\n",
      "Processing backdoor-trigger-recovery/0122014648...\n",
      "Processing perception_temporal_action_loc/0130064726...\n",
      "Processing perception_temporal_action_loc/0130104224...\n",
      "Processing perception_temporal_action_loc/0130021740...\n",
      "Processing perception_temporal_action_loc/0130045001...\n",
      "Processing perception_temporal_action_loc/0130093111...\n",
      "Processing perception_temporal_action_loc/0130112112...\n",
      "Processing perception_temporal_action_loc/0130102918...\n",
      "Processing perception_temporal_action_loc/0130102836...\n",
      "Compiled summaries saved to Steps_RP/compiled_summaries.csv and Steps_RP/compiled_summaries.xlsx\n",
      "Failed folders list saved to Steps_RP/failed_folders.txt\n",
      "Retry statistics saved to Steps_RP/retry_stats.txt\n",
      "Total failed folders: 0\n",
      "Folders that needed retries: 0\n"
     ]
    }
   ],
   "source": [
    "# Process all the files\n",
    "results = process_and_analyze_files(\"Steps_RP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_research_plan_to_csv(csv_path, steps_dir):\n",
    "    \"\"\"\n",
    "    Reads an existing CSV, extracts the last research plan for each entry,\n",
    "    and adds it as a new column to the CSV.\n",
    "    \n",
    "    Args:\n",
    "        csv_path (str): Path to the existing CSV file\n",
    "        steps_dir (str): Directory containing the Steps folders\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with the new column\n",
    "    \"\"\"\n",
    "    # Read the existing CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Add the new column\n",
    "    df['Last_Research_Plan'] = \"\"\n",
    "    \n",
    "    # Iterate through each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        task_name = row['Task']\n",
    "        run_id = row['Run_ID']\n",
    "        \n",
    "        # Construct the path to the output.json file\n",
    "        output_file = os.path.join(steps_dir, task_name, str(run_id), \"output.json\")\n",
    "        \n",
    "        # Extract the last research plan\n",
    "        last_research_plan = \"\"\n",
    "        try:\n",
    "            if os.path.exists(output_file):\n",
    "                with open(output_file, 'r') as f:\n",
    "                    output_data = json.load(f)\n",
    "                \n",
    "                # Extract the research plan from the last step's action field\n",
    "                if output_data and len(output_data) > 0:\n",
    "                    last_step = output_data[-1]\n",
    "                    if (isinstance(last_step, dict) and \n",
    "                        \"action\" in last_step and \n",
    "                        isinstance(last_step[\"action\"], dict) and \n",
    "                        \"Research Plan and Status\" in last_step[\"action\"]):\n",
    "                        last_research_plan = last_step[\"action\"][\"Research Plan and Status\"]\n",
    "                    else:\n",
    "                        print(f\"No 'Research Plan and Status' found in last step for {task_name}/{run_id}\")\n",
    "            else:\n",
    "                print(f\"Output file not found: {output_file}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting research plan for {task_name}/{run_id}: {str(e)}\")\n",
    "            last_research_plan = \"Error: Could not extract research plan\"\n",
    "        \n",
    "        # Update the DataFrame\n",
    "        df.at[index, 'Last_Research_Plan'] = last_research_plan\n",
    "        \n",
    "        # Print progress every 10 rows\n",
    "        if (index + 1) % 10 == 0:\n",
    "            print(f\"Processed {index + 1}/{len(df)} entries...\")\n",
    "    \n",
    "    # Save the updated CSV\n",
    "    output_path = csv_path.replace('.csv', '_with_research_plan.csv')\n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    # Also save as Excel for easier viewing\n",
    "    excel_path = output_path.replace('.csv', '.xlsx')\n",
    "    df.to_excel(excel_path, index=False)\n",
    "    \n",
    "    print(f\"Updated CSV saved to {output_path}\")\n",
    "    print(f\"Updated Excel saved to {excel_path}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10/40 entries...\n",
      "Processed 20/40 entries...\n",
      "Processed 30/40 entries...\n",
      "Processed 40/40 entries...\n",
      "Updated CSV saved to Steps_RP/compiled_summaries_with_research_plan.csv\n",
      "Updated Excel saved to Steps_RP/compiled_summaries_with_research_plan.xlsx\n",
      "\n",
      "Sample data from updated DataFrame:\n",
      "                 Task              Run_ID  \\\n",
      "0  machine_unlearning   0203205627_279760   \n",
      "1  machine_unlearning  0203205627_2107738   \n",
      "2  machine_unlearning  0204004906_2156777   \n",
      "3  machine_unlearning  0204021048_1005508   \n",
      "4  machine_unlearning   0204000906_980483   \n",
      "\n",
      "                                             Summary  \\\n",
      "0  The agent employed a scientific research appro...   \n",
      "1  The agent primarily employed a scientific rese...   \n",
      "2  The agent employed a scientific research appro...   \n",
      "3  The agent primarily employed a scientific rese...   \n",
      "4  The agent primarily took a scientific research...   \n",
      "\n",
      "                                  Last_Research_Plan  \n",
      "0   \\n1. Environment and code exploration [COMPLE...  \n",
      "1           \\n1. Understand the problem setup and...  \n",
      "2        \\n1. Examine available files and methods...  \n",
      "3  \\n1. Understand the Problem Requirements ✓\\n  ...  \n",
      "4                                                ...  \n"
     ]
    }
   ],
   "source": [
    "csv_path = \"Steps_RP/compiled_summaries.csv\"\n",
    "    \n",
    "# Path to the Steps directory\n",
    "steps_dir = \"Steps_RP\"\n",
    "\n",
    "# Add the research plan column\n",
    "updated_df = add_research_plan_to_csv(csv_path, steps_dir)\n",
    "\n",
    "# Display some sample data\n",
    "print(\"\\nSample data from updated DataFrame:\")\n",
    "print(updated_df[['Task', 'Run_ID', 'Summary', 'Last_Research_Plan']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
